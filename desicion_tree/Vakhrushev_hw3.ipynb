{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 25 ноября 2019, 15:00   \n",
    "**Штраф за опоздание:** -2 балла после 15:00 25 ноября, -4 балла после 15:00 2 декабря, -6 баллов после 15:00 9 декабря  -8 баллов после 15:00 16 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0919, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) и [Speed Dating Data](https://cloud.mail.ru/public/8nHV/p6J7wY1y1)\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "            self.G_spec_fun = self.__gini_spec\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "            self.G_spec_fun = self.__entropy_spec\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "            self.G_spec_fun = self.__misclass_spec\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - (((l_c + r_c) / (l_s + r_s)) ** 2 ).sum(axis = 1) -\\\n",
    "        ((1 - l_c ** 2 / l_s + 1 - r_c ** 2 / r_s) /  (l_s + r_s)).sum(axis=1) \n",
    "    \n",
    "    def __gini_spec(self, y_c, y_s):\n",
    "        return 1 - ((np.bincount(y_c).astype(np.float) / y_s) ** 2).sum()\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return -((l_c + r_c) / (l_s + r_s) * np.log((l_c + r_c) / (l_s + r_s))).sum(axis = 1) +\\\n",
    "        ((l_c * np.log(l_c / l_s) + r_c * np.log(r_c / r_c)) / (l_s + r_s)).sum(axis=1)\n",
    "    \n",
    "    def __entropy_spec(self, l_c, l_s, r_c, r_s):\n",
    "        return -np.sum(np.bincount(y).astype(np.float) / y.size *\\\n",
    "        np.log(np.bincount(y).astype(np.float) / y.size))\n",
    "    \n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return -np.max((l_c + r_c) / (l_s + r_s), axis = 1) +\\\n",
    "        (np.max(l_c / (r_s + l_s), axis = 1) + np.max(r_c / (r_s + l_s), axis = 1)) - 1\n",
    "                 \n",
    "    def __misclass_spec(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - np.max(np.bincount(y).astype(np.float) / y.size)\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:round(np.sqrt(n_feature))])\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:round(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = self.num_class\n",
    "        borders = np.where(sorted_y[:-1] != sorted_y[1:])[0]\n",
    "        if len(borders) == 0:\n",
    "            return np.inf, None\n",
    "        #сколько одинаковых подряд идет\n",
    "        equals = borders - np.append(np.array([-1]), borders[:-1])\n",
    "        #какому классу принадлежит отрезок\n",
    "        what_class_rules_the_range = np.zeros((equals.shape[0],class_number))\n",
    "        what_class_rules_the_range[np.arange(equals.shape[0]), sorted_y[borders]] = 1\n",
    "        increments = what_class_rules_the_range * equals.reshape(-1, 1)\n",
    "        \n",
    "        l_class_count = np.cumsum(increments, axis = 0)\n",
    "        r_class_count = np.bincount(sorted_y, minlength = class_number) - l_class_count\n",
    "        \n",
    "        l_sizes = borders.reshape(l_class_count.shape[0], 1) + 1\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes \n",
    "        weights = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmax(weights)\n",
    "        element_id = l_sizes[idx][0]\n",
    "        return weights[idx], (sorted_x[element_id-1] + sorted_x[element_id]) / 2.0\n",
    "    \n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        #старые значения классов\n",
    "        f = np.array(y)\n",
    "        if self.max_depth != None and depth >= self.max_depth or\\\n",
    "                    y.shape[0] < self.min_samples_split or\\\n",
    "                    self.sufficient_share <= np.bincount(y).max() / y.size:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(np.float) / y.size)\n",
    "        #отображает множество значений классов в множество вида [1..N]\n",
    "        t = dict()\n",
    "        i = 0\n",
    "        for j in range(y.shape[0]):\n",
    "            if y[j] not in t.keys():\n",
    "                t.update({y[j]:i})\n",
    "                y[j] = i\n",
    "                i += 1\n",
    "            else:\n",
    "                y[j] = t[y[j]]\n",
    "                \n",
    "        ids = np.arange(x.shape[1])\n",
    "        thresholds = np.array([self.__find_threshold(x[:, idx], y) for idx in range(x.shape[1])])\n",
    "        best = thresholds[:, 0].argmax()\n",
    "        best_thresh = thresholds[best, 1]\n",
    "        \n",
    "        if best_thresh is None:\n",
    "            tmp = np.bincount(f)\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, tmp.argmax(), tmp.astype(np.float) / y.size)\n",
    "            return\n",
    "        \n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, f, ids[best], best_thresh)\n",
    "        if y_l.shape[0] == 0 or y_r.shape[0] == 0:\n",
    "            tmp = np.bincount(y)\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, tmp.argmax(), tmp.astype(np.float) / y.size)\n",
    "            return\n",
    "        \n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, ids[best], best_thresh)\n",
    "        self.feature_importances_[best] += self.G_spec_fun(y, y.shape[0]) - y_l.shape[0] / y.shape[0] * \\\n",
    "        self.G_spec_fun(y_l, y_l.shape[0]) - y_r.shape[0] / y.shape[0] * self.G_spec_fun(y_r, y_r.shape[0])\n",
    "        self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "        self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "        return \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1], dtype=np.float)\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "        self.feature_importances_ /= self.feature_importances_.sum()\n",
    "        \n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split = 2)\n",
    "clf = DecisionTreeClassifier(min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.61 ms, sys: 806 µs, total: 7.42 ms\n",
      "Wall time: 4.12 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.6 ms, sys: 642 µs, total: 31.2 ms\n",
      "Wall time: 27.5 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8311688311688311"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred = clf.predict(X_test), y_true = y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9474747474747475"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred = my_clf.predict(X_test), y_true = y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Speed Dating Data.csv', encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int',\n",
    "              'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'dec_o', 'attr_o',\n",
    "              'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o',\n",
    "             'prob_o', 'met_o',\n",
    "           'partner','order','position', 'positin1',\n",
    "               'round', 'condtn', 'idg', 'id',  \n",
    "           'sports', 'tvsports', \n",
    "           'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming',\n",
    "           'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts',\n",
    "           'music', 'shopping', 'yoga', 'expnum', 'wave']\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, :95]\n",
    "\n",
    "df = df.drop(to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = ['field_cd', 'mn_sat', 'tuition', 'income', 'career_c' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "\n",
    "df.loc[:,info] = df.loc[:,info].fillna(0)\n",
    "\n",
    "df_he = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid']) \\\n",
    "            .drop(['gender'], axis = 1).dropna()\n",
    "\n",
    "df_she = df.query('gender == 0').drop_duplicates(subset=['iid']) \\\n",
    "            .drop(['gender', 'match', 'int_corr', 'samerace'], axis = 1).dropna()\n",
    "\n",
    "df_she.columns = df_she.columns + '_s'\n",
    "df_she = df_she.drop(['pid_s'], axis = 1)\n",
    "df_pair = df_he.join(df_she.set_index('iid_s'), on = 'pid', how = 'inner')\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "\n",
    "features_names = df_pair.columns[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in df_pair.columns:\n",
    "    k = df_pair[j].isnull().sum()\n",
    "    if  type(df_pair[j][df_pair[j].first_valid_index()]) is str:\n",
    "        df_pair = df_pair.drop([j], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>mn_sat</th>\n",
       "      <th>tuition</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>...</th>\n",
       "      <th>amb2_1_s</th>\n",
       "      <th>shar2_1_s</th>\n",
       "      <th>attr3_1_s</th>\n",
       "      <th>sinc3_1_s</th>\n",
       "      <th>fun3_1_s</th>\n",
       "      <th>intel3_1_s</th>\n",
       "      <th>amb3_1_s</th>\n",
       "      <th>attr5_1_s</th>\n",
       "      <th>sinc5_1_s</th>\n",
       "      <th>intel5_1_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>26908.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>9168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3534</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>26062.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>26908.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8245</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8289</td>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8311</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8355</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>26019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8377</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1740 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      match  int_corr  samerace   age  field_cd  mn_sat  tuition  race  \\\n",
       "3507      0      0.05         0  32.0       7.0  1430.0  26908.0   2.0   \n",
       "3516      0      0.44         0  25.0      10.0  1140.0   9168.0   2.0   \n",
       "3525      0     -0.20         0  25.0      10.0     0.0      0.0   4.0   \n",
       "3534      0      0.23         1  27.0       8.0  1360.0  26062.0   6.0   \n",
       "3508      0      0.43         1  32.0       7.0  1430.0  26908.0   2.0   \n",
       "...     ...       ...       ...   ...       ...     ...      ...   ...   \n",
       "8245      0      0.13         0  30.0       8.0     0.0      0.0   2.0   \n",
       "8289      0      0.23         0  30.0       8.0     0.0      0.0   2.0   \n",
       "8311      0      0.29         0  28.0       8.0     0.0      0.0   2.0   \n",
       "8355      0     -0.32         0  27.0       8.0  1400.0  26019.0   1.0   \n",
       "8377      0      0.01         0  25.0      18.0     0.0      0.0   2.0   \n",
       "\n",
       "      imprace  imprelig  ...  amb2_1_s  shar2_1_s  attr3_1_s  sinc3_1_s  \\\n",
       "3507      1.0       6.0  ...      10.0       10.0        7.0        7.0   \n",
       "3516      7.0       1.0  ...      10.0       10.0        7.0        7.0   \n",
       "3525      1.0       1.0  ...      10.0       10.0        7.0        7.0   \n",
       "3534      1.0       1.0  ...      10.0       10.0        7.0        7.0   \n",
       "3508      1.0       6.0  ...      10.0       20.0        6.0        9.0   \n",
       "...       ...       ...  ...       ...        ...        ...        ...   \n",
       "8245      3.0       4.0  ...      10.0       20.0        3.0        9.0   \n",
       "8289      8.0       8.0  ...      10.0       20.0        3.0        9.0   \n",
       "8311      2.0       3.0  ...      10.0       20.0        3.0        9.0   \n",
       "8355      2.0       1.0  ...      10.0       20.0        3.0        9.0   \n",
       "8377      1.0       1.0  ...      10.0       20.0        3.0        9.0   \n",
       "\n",
       "      fun3_1_s  intel3_1_s  amb3_1_s  attr5_1_s  sinc5_1_s  intel5_1_s  \n",
       "3507       8.0         8.0      10.0        9.0        6.0         9.0  \n",
       "3516       8.0         8.0      10.0        9.0        6.0         9.0  \n",
       "3525       8.0         8.0      10.0        9.0        6.0         9.0  \n",
       "3534       8.0         8.0      10.0        9.0        6.0         9.0  \n",
       "3508       9.0         8.0       9.0        6.0        9.0         9.0  \n",
       "...        ...         ...       ...        ...        ...         ...  \n",
       "8245       9.0         9.0       7.0        3.0        9.0         9.0  \n",
       "8289       9.0         9.0       7.0        3.0        9.0         9.0  \n",
       "8311       9.0         9.0       7.0        3.0        9.0         9.0  \n",
       "8355       9.0         9.0       7.0        3.0        9.0         9.0  \n",
       "8377       9.0         9.0       7.0        3.0        9.0         9.0  \n",
       "\n",
       "[1740 rows x 81 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pair.iloc[:, 1:].values\n",
    "y = df_pair.iloc[:, 0].values\n",
    "features_names = df_pair.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "my_clf = MyDecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([597,  99]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([873, 171]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.4 ms, sys: 17 µs, total: 29.4 ms\n",
      "Wall time: 27.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 261 ms, sys: 470 µs, total: 262 ms\n",
      "Wall time: 259 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5213728646671772"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5369031540478271"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = np.argpartition(clf.feature_importances_, -10)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02283022, 0.02358793, 0.02439176, 0.02779535, 0.02455049,\n",
       "       0.03298889, 0.03781866, 0.03545336, 0.03495655, 0.09502328])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_[imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_imp = np.argpartition(my_clf.feature_importances_, -10)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02224843, 0.11146861, 0.06571816, 0.06690328, 0.0818953 ,\n",
       "       0.06499627, 0.0451363 , 0.13270072, 0.09952554, 0.265254  ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.feature_importances_[my_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022830224844819554   shar1_1\n",
      "0.023587934440758306   amb1_1_s\n",
      "0.02439175602496279   shar1_1_s\n",
      "0.02779534660525798   amb3_1_s\n",
      "0.024550494219512126   amb4_1_s\n",
      "0.03298889268064489   age_s\n",
      "0.03781866236079214   sinc1_1_s\n",
      "0.0354533576226882   income_s\n",
      "0.03495654683934662   exphappy_s\n",
      "0.09502328452126206   int_corr\n"
     ]
    }
   ],
   "source": [
    "for i in imp:\n",
    "    print(clf.feature_importances_[i],' ',features_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022248434428592555   shar1_1\n",
      "0.11146860591347865   fun4_1_s\n",
      "0.0657181631373654   intel1_1\n",
      "0.06690328033497481   imprelig_s\n",
      "0.08189530230378021   tuition_s\n",
      "0.06499627166966686   field_cd_s\n",
      "0.04513629977060201   fun2_1\n",
      "0.13270072132556976   samerace\n",
      "0.09952554099417736   age\n",
      "0.2652539974052223   int_corr\n"
     ]
    }
   ],
   "source": [
    "for i in my_imp:\n",
    "    print(my_clf.feature_importances_[i],' ',features_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 901, 'min_samples_leaf': 12, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators':range(1, 1000,100),\n",
    "    'max_depth':range(1,20),\n",
    "    'min_samples_leaf': range(1,20, 1),\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "find_best = RandomizedSearchCV(rf_clf, param_distributions = params, cv = 5)\n",
    "find_best.fit(X_train, y_train)\n",
    "print(find_best.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
